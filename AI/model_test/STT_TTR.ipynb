{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ccaaf09-93af-4e37-bde0-4da629363448",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T07:35:23.805597Z",
     "iopub.status.busy": "2025-03-27T07:35:23.805306Z",
     "iopub.status.idle": "2025-03-27T07:35:24.330956Z",
     "shell.execute_reply": "2025-03-27T07:35:24.330176Z",
     "shell.execute_reply.started": "2025-03-27T07:35:23.805575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/20203068\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ef30fb-1b43-46c4-94a7-604c361e772d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T07:36:26.845513Z",
     "iopub.status.busy": "2025-03-27T07:36:26.845175Z",
     "iopub.status.idle": "2025-03-27T07:37:29.536001Z",
     "shell.execute_reply": "2025-03-27T07:37:29.535396Z",
     "shell.execute_reply.started": "2025-03-27T07:36:26.845489Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from openai import OpenAI\n",
    "import re\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# OpenAI GPT-4o 키\n",
    "client = OpenAI(api_key=\"sMA\") \n",
    "\n",
    "# 감정 라벨\n",
    "emotion_labels = [\"기쁨\", \"슬픔\", \"외로움\", \"두려움\", \"평온\", \"설렘\", \"신남\", \"분노\"]\n",
    "\n",
    "# STT 모델 (Whisper) 로드 \n",
    "stt_model_id = \"openai/whisper-small\"\n",
    "stt_model = AutoModelForSpeechSeq2Seq.from_pretrained(stt_model_id).to(device)\n",
    "stt_processor = AutoProcessor.from_pretrained(stt_model_id)\n",
    "\n",
    "stt_pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=stt_model,\n",
    "    tokenizer=stt_processor.tokenizer,\n",
    "    feature_extractor=stt_processor.feature_extractor,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# 대화 상태 저장 \n",
    "chat_history = [\n",
    "    {\"role\": \"system\", \"content\": \"너는 독거노인과 따뜻하게 대화하는 친구야. 질문도 하면서 친절하게 말해줘.\"}\n",
    "]\n",
    "\n",
    "# GPT 대화 응답 함수\n",
    "def generate_chat_response(chat_history):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=chat_history,\n",
    "        max_tokens=500,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# 감정 분석 함수\n",
    "def analyze_emotion_from_history(chat_history):\n",
    "    messages = chat_history + [{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"지금까지의 사용자와 AI 간의 전체 대화를 바탕으로 감정을 하나로 분석해줘. 감정: \" + \", \".join(emotion_labels) + \" 중 하나로 '감정: [감정]' 형식으로 말해줘.\"\n",
    "    }]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        max_tokens=300,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "\n",
    "    gpt_reply = response.choices[0].message.content\n",
    "    emotion_match = re.search(r\"감정:\\s*(\\w+)\", gpt_reply)\n",
    "    emotion = emotion_match.group(1) if emotion_match else \"분석 실패\"\n",
    "    return emotion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32ff7d13-8f51-4a7d-8ca0-20c4205d410b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T07:38:07.197080Z",
     "iopub.status.busy": "2025-03-27T07:38:07.196616Z",
     "iopub.status.idle": "2025-03-27T07:38:26.694060Z",
     "shell.execute_reply": "2025-03-27T07:38:26.693379Z",
     "shell.execute_reply.started": "2025-03-27T07:38:07.197051Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/gatoai/python/venv/3.10/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whisper 결과:  태풍에 대한 기억은 옛날에 매일 민간 올 때 제가 울렁도 있었거든요.\n",
      "GPT 응답: 울렁도에 사셨군요! 그곳은 정말 아름다운 섬으로 유명하죠. 태풍이 올 때면 바람과 파도가 정말 무섭고 위험했을 것 같아요. 그 시절에는 어떻게 대처하셨나요? 가족이나 이웃들과 함께 대피하셨나요?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/gatoai/python/venv/3.10/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whisper 결과:  그 이틀에도 우리가 나오지 못했어요\n",
      "GPT 응답: 정말 힘든 시간이었겠어요. 이틀 동안 집 안에만 계셔야 했다니 불안하고 답답하셨을 것 같아요. 그때는 가족들이랑 어떻게 시간을 보내셨나요? 혹시 그 경험을 통해 배우신 점이나 특별한 기억이 있으신가요?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/gatoai/python/venv/3.10/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whisper 결과:  그 때 호텔에서 이렇게 내다보는데 얼마나 태풍이 불면 차가 막 뒤로 움직이더라고\n",
      "GPT 응답: 정말 무서운 경험이셨겠어요. 차가 뒤로 움직일 정도면 바람이 아주 강했을 텐데, 안전한 곳에 계셔서 다행이에요. 그런 상황에서는 아무래도 마음이 많이 불안했을 텐데, 그때 어떻게 마음을 가라앉히셨나요? 혹시 주변에 같이 계셨던 분들과 서로 의지하셨나요?\n",
      " 현재 chat_history 상태:\n",
      "system: 너는 독거노인과 따뜻하게 대화하는 친구야. 질문도 하면서 친절하게 말해줘.\n",
      "user:  태풍에 대한 기억은 옛날에 매일 민간 올 때 제가 울렁도 있었거든요.\n",
      "assistant: 울렁도에 사셨군요! 그곳은 정말 아름다운 섬으로 유명하죠. 태풍이 올 때면 바람과 파도가 정말 무섭고 위험했을 것 같아요. 그 시절에는 어떻게 대처하셨나요? 가족이나 이웃들과 함께 대피하셨나요?\n",
      "user:  그 이틀에도 우리가 나오지 못했어요\n",
      "assistant: 정말 힘든 시간이었겠어요. 이틀 동안 집 안에만 계셔야 했다니 불안하고 답답하셨을 것 같아요. 그때는 가족들이랑 어떻게 시간을 보내셨나요? 혹시 그 경험을 통해 배우신 점이나 특별한 기억이 있으신가요?\n",
      "user:  그 때 호텔에서 이렇게 내다보는데 얼마나 태풍이 불면 차가 막 뒤로 움직이더라고\n",
      "assistant: 정말 무서운 경험이셨겠어요. 차가 뒤로 움직일 정도면 바람이 아주 강했을 텐데, 안전한 곳에 계셔서 다행이에요. 그런 상황에서는 아무래도 마음이 많이 불안했을 텐데, 그때 어떻게 마음을 가라앉히셨나요? 혹시 주변에 같이 계셨던 분들과 서로 의지하셨나요?\n",
      " 전체 대화 감정 분석 결과: 두려움\n"
     ]
    }
   ],
   "source": [
    "def stt_to_ttr(audio_file):\n",
    "    stt_result = stt_pipe(audio_file)\n",
    "    user_input = stt_result[\"text\"]\n",
    "    print(\"Whisper 결과:\", user_input)\n",
    "\n",
    "    chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "    reply = generate_chat_response(chat_history)\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": reply})\n",
    "\n",
    "    print(\"GPT 응답:\", reply)\n",
    "\n",
    "# # 테스트 실행 \n",
    "# audio_file = \"Gyeongsangdo/wavs/say_set1_collectorgs25_speakergs2215_15_0_16_3.wav\"\n",
    "# stt_to_ttr(audio_file)\n",
    "\n",
    "# # 감정 분석\n",
    "# final_emotion = analyze_emotion_from_history(chat_history)\n",
    "# print(f\"전체 대화 감정 분석 결과: {final_emotion}\")\n",
    "\n",
    "# 대화 1\n",
    "stt_to_ttr(\"Gyeongsangdo/wavs/say_set2_collectorgs131_speakergs1126_32_0_43_1.wav\")\n",
    "\n",
    "# 대화 2\n",
    "stt_to_ttr(\"Gyeongsangdo/wavs/say_set2_collectorgs131_speakergs1126_32_0_43_2.wav\")\n",
    "\n",
    "# 대화 3\n",
    "stt_to_ttr(\"Gyeongsangdo/wavs/say_set2_collectorgs131_speakergs1126_32_0_43_4.wav\")\n",
    "\n",
    "# 대화 로그 확인\n",
    "print(\" 현재 chat_history 상태:\")\n",
    "for msg in chat_history:\n",
    "    print(f\"{msg['role']}: {msg['content']}\")\n",
    "\n",
    "# 감정 분석\n",
    "final_emotion = analyze_emotion_from_history(chat_history)\n",
    "print(f\" 전체 대화 감정 분석 결과: {final_emotion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e992b45-c6f2-400d-8a46-7b768583639e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.6.0 (py3.10)",
   "language": "python",
   "name": "pytorch-2.6.0-cuda12.4-py3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
